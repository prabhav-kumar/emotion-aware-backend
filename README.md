# Emotion-Aware Virtual Classroom

> **NEW: Dual-Extension Architecture** - Students and teachers use separate extensions with real-time backend aggregation.

A revolutionary system for emotion detection in virtual classrooms using **two Chrome extensions** (student + teacher) connected via a **backend server** for real-time emotion aggregation and AI-powered teaching insights.

## ğŸ¯ Why Dual Extensions?

**Problem Solved:** The original single-extension approach stopped working when teachers switched tabs to OneNote, PowerPoint, or other apps.

**Solution:** Separate extensions with backend aggregation:
- âœ… **Tab Independent**: Teacher can switch apps freely
- âœ… **Enhanced Privacy**: Students analyze their own video
- âœ… **Scalable**: Backend handles real-time aggregation
- âœ… **Professional**: Production-ready architecture

## âœ¨ Features

### Student Extension
- **ğŸ˜Š Self-Analysis**: Analyzes student's own video (self-view)
- **ğŸ“¡ Real-time Sync**: Sends emotion data every 3 seconds
- **ğŸ”’ Privacy-First**: Only emotion percentages sent, never video
- **ğŸ›ï¸ Simple UI**: Connection status and current emotion

### Teacher Extension
- **ğŸ“Š Aggregated Dashboard**: View all students' emotions combined
- **ğŸ¨ Persistent Overlay**: Works even when switching tabs
- **ğŸ™ï¸ Live Transcription**: Captures speech in real-time
- **ğŸ¤– AI Insights**: Gemini-powered teaching suggestions
- **ğŸ‘¥ Session Management**: Create/join classroom sessions

### Backend Server
- **âš¡ Real-time**: WebSocket-based instant updates
- **ğŸ”— Session Management**: Handle multiple classrooms
- **ğŸ“ˆ Aggregation**: Smart emotion averaging
- **ğŸ§¹ Auto-cleanup**: Removes inactive sessions

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Student 1  â”‚         â”‚   Teacher   â”‚
â”‚  Extension  â”‚         â”‚  Extension  â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â–²â”€â”€â”€â”€â”€â”€â”˜
       â”‚                       â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”
â”‚  Student 2  â”‚         â”‚  Aggregated â”‚
â”‚  Extension  â”‚  â”€â”€â”€â”€â”€â–¶ â”‚    Data     â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚                       â–²
       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
           â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
           â”‚ Backend Server â”‚
           â”‚  (Node.js+WS)  â”‚
           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ› ï¸ Tech Stack

- **Student Extension**: Vanilla JS, face-api.js, WebSocket
- **Teacher Extension**: Vanilla JS, Web Speech API, Gemini API
- **Backend**: Node.js, ws (WebSocket library)
- **Emotion Detection**: face-api.js (TinyFaceDetector)
- **AI**: Google Gemini 2.0 Flash
- **Protocol**: Chrome Manifest V3

## ğŸ“‹ Prerequisites

1. **Google Chrome/Edge** (Chromium-based browser)
2. **Node.js** (v14+) - [Download here](https://nodejs.org/)
3. **Gemini API Key** - Get it from [Google AI Studio](https://makersuite.google.com/app/apikey)

## âš¡ Quick Start (5 Minutes)

### Option 1: Automated Setup (Windows)

```powershell
# 1. Download face-api.js
.\download-face-api.ps1

# 2. Start backend
.\START_BACKEND.bat

# 3. Load extensions in Chrome (see below)
```

### Option 2: Manual Setup

**See detailed guide:** [`SETUP_GUIDE.md`](SETUP_GUIDE.md)

## ğŸš€ Installation Steps

### 1. Setup Backend Server

```bash
cd backend-server
npm install
npm start
```

Server runs on `ws://localhost:3000` âœ…

### 2. Setup Student Extension

**Download face-api.js:**
```bash
cd student-extension/libs
# Download from: https://cdn.jsdelivr.net/npm/@vladmandic/face-api@1.7.12/dist/face-api.min.js
```

**Create icons:** 16x16, 48x48, 128x128 PNG in `student-extension/icons/`

**Load in Chrome:**
- Go to `chrome://extensions/`
- Enable "Developer mode"
- "Load unpacked" â†’ select `student-extension/`

### 3. Setup Teacher Extension

**Create icons:** Same sizes in `teacher-extension/icons/`

**Load in Chrome** (different profile or Edge):
- Go to `chrome://extensions/`
- Enable "Developer mode"  
- "Load unpacked" â†’ select `teacher-extension/`

## ğŸ“– Usage Guide

### For Teachers:

1. **Start Backend**: Run `npm start` in `backend-server/`
2. **Open Google Meet**: Start or join meeting
3. **Create Session**: 
   - Click teacher extension icon
   - Click "Create New Session"
   - Share Session ID with students (e.g., "ABC123")
4. **Configure Gemini** (first time): Enter API key
5. **Start Transcription**: Click "Start Transcription" button
6. **Monitor**: View overlay in Google Meet showing aggregated emotions
7. **Get Insights**: Click "Generate Insights from Gemini"

### For Students:

1. **Join Google Meet**: Enter meeting
2. **Turn On Camera**: Required for emotion detection
3. **Connect to Session**:
   - Click student extension icon
   - Server: `ws://localhost:3000`
   - Session ID: (from teacher)
   - Your Name: Enter your name
   - Click "Connect to Session"
4. **Done!**: Extension runs in background

### Understanding the Data

**Teacher Overlay Shows:**
- **Engaged %**: Average engagement across all students
- **Confused %**: Students showing confusion
- **Active Students**: Count of students with cameras on
- **Emotion Breakdown**: Distribution of emotions

**Student Popup Shows:**
- Connection status
- Your current dominant emotion
- Session info

## ğŸ”§ Troubleshooting

### "Cannot connect to backend"
```bash
# Check if server is running (Windows)
netstat -an | findstr :3000

# Restart backend
cd backend-server
npm start
```
- Try `ws://127.0.0.1:3000` instead of `localhost`
- Check firewall settings

### "Face detection not working"
- Verify `student-extension/libs/face-api.min.js` exists (should be ~1-2MB)
- Check camera permissions in browser
- Ensure face is visible and well-lit in self-view

### "No emotion data in teacher view"
- Verify students are connected (check their extension popup)
- Confirm Session ID matches (case-sensitive!)
- Check browser console (F12) for WebSocket errors
- Ensure backend server is running

### Transcription not working
- Grant microphone permissions to Google Meet
- Chrome/Edge only (Web Speech API)
- Reload the Meet page

### Gemini API errors
- Verify API key is correct
- Check API quota at [Google Cloud Console](https://console.cloud.google.com/)
- Try using `gemini-2.0-flash-exp` or `gemini-1.5-flash`

**For detailed troubleshooting:** See [`SETUP_GUIDE.md`](SETUP_GUIDE.md)

## ğŸ—ï¸ Project Structure

```
emotion-aware-classroom/
â”œâ”€â”€ student-extension/              # Student browser extension
â”‚   â”œâ”€â”€ manifest.json
â”‚   â”œâ”€â”€ background.js              # WebSocket client
â”‚   â”œâ”€â”€ content/
â”‚   â”‚   â”œâ”€â”€ content.js            # Main coordinator
â”‚   â”‚   â””â”€â”€ emotionDetector.js    # Self-video analysis
â”‚   â”œâ”€â”€ popup/
â”‚   â”‚   â”œâ”€â”€ popup.html            # Connection UI
â”‚   â”‚   â”œâ”€â”€ popup.css
â”‚   â”‚   â””â”€â”€ popup.js
â”‚   â”œâ”€â”€ libs/
â”‚   â”‚   â””â”€â”€ face-api.min.js       # Face detection library
â”‚   â””â”€â”€ icons/
â”‚
â”œâ”€â”€ teacher-extension/              # Teacher browser extension
â”‚   â”œâ”€â”€ manifest.json
â”‚   â”œâ”€â”€ background.js              # WebSocket client + session mgmt
â”‚   â”œâ”€â”€ content/
â”‚   â”‚   â”œâ”€â”€ content.js            # Main coordinator
â”‚   â”‚   â”œâ”€â”€ overlay.js            # Persistent overlay
â”‚   â”‚   â”œâ”€â”€ overlay.css
â”‚   â”‚   â””â”€â”€ transcription.js      # Speech recognition
â”‚   â”œâ”€â”€ popup/
â”‚   â”‚   â”œâ”€â”€ popup.html            # Dashboard UI
â”‚   â”‚   â”œâ”€â”€ popup.css
â”‚   â”‚   â””â”€â”€ popup.js              # Gemini integration
â”‚   â””â”€â”€ icons/
â”‚
â”œâ”€â”€ backend-server/                 # Node.js WebSocket server
â”‚   â”œâ”€â”€ package.json
â”‚   â”œâ”€â”€ server.js                  # Main server logic
â”‚   â””â”€â”€ README.md
â”‚
â”œâ”€â”€ README.md                       # This file - main documentation
â”œâ”€â”€ SETUP_GUIDE.md                  # Step-by-step setup guide
â”œâ”€â”€ download-face-api.ps1           # Helper script for dependencies
â”œâ”€â”€ START_BACKEND.bat               # Windows backend launcher
â””â”€â”€ LICENSE                         # MIT License
```

## ğŸ” Privacy & Security

### Student Privacy
- **Self-Analysis Only**: Students analyze their OWN video (self-view)
- **No Video Upload**: Videos never leave the student's browser
- **Emotion Percentages Only**: Only numerical percentages sent to backend
- **Explicit Consent**: Students must install extension and connect
- **Full Control**: Can disconnect anytime

### Teacher Privacy
- **Aggregated Data Only**: Teacher receives combined statistics
- **No Individual Tracking**: Cannot see individual student emotions
- **Local Transcription**: Speech stays local until Gemini API call
- **Secure Keys**: API keys encrypted in browser storage

### Backend Security
- **No Storage**: Backend doesn't store historical data
- **Session-Based**: Data cleared when session ends
- **Local Network**: Recommended to run on local machine/network
- **Upgradable**: Easy to add TLS (wss://) for production

## ğŸ¯ Key Technical Decisions

1. **Dual Extensions**: Solves tab-switching problem
2. **WebSocket Backend**: Real-time aggregation at scale
3. **Student Self-Analysis**: Better privacy + accuracy
4. **face-api.js**: Privacy-first emotion detection
5. **Persistent Overlay**: Teacher can multitask
6. **Session Management**: Multiple classrooms supported

## ğŸš§ Limitations

### Current Limitations
- Backend server required (can't run extensions alone)
- Requires students to have cameras ON
- Works best with good lighting conditions
- Emotion detection accuracy ~70-80%
- Local network recommended (latency)
- Basic authentication (production needs more)

### Browser Support
- Chrome/Edge (Chromium) only
- Web Speech API for transcription
- WebSocket support required

## ğŸ”® Future Enhancements

### Planned Features
- [ ] Historical emotion analytics dashboard
- [ ] Session recording and export
- [ ] Multi-language transcription
- [ ] Mobile app support
- [ ] LMS integration (Canvas, Moodle, etc.)
- [ ] Advanced authentication (JWT, OAuth)
- [ ] Cloud deployment guides (AWS, Heroku)
- [ ] Emotion trend graphs
- [ ] Student self-reflection dashboard
- [ ] Breakout room support

## ğŸ“š Documentation

This project includes two main documentation files:

| Document | Description |
|----------|-------------|
| [`README.md`](README.md) | Main overview, features, and quick start (this file) |
| [`SETUP_GUIDE.md`](SETUP_GUIDE.md) | Detailed step-by-step setup instructions |
| [`backend-server/README.md`](backend-server/README.md) | Backend server API documentation |

## ğŸ“„ License

MIT License - Feel free to use, modify, and distribute.

## ğŸ¤ Credits & Acknowledgments

- **face-api.js** by Vladimir Mandic - Client-side emotion detection
- **Google Gemini API** - AI-powered teaching insights
- **Web Speech API** - Browser native transcription
- **ws (WebSocket library)** - Real-time communication
- **Node.js** - Backend server platform

## ğŸ“§ Support & Troubleshooting

**Quick Checks:**
1. Backend server running? (`npm start` in `backend-server/`)
2. Extensions loaded? (Check `chrome://extensions/`)
3. Session IDs match? (Case-sensitive)
4. Browser console errors? (F12 â†’ Console)

**Documentation:**
- Setup issues â†’ [`SETUP_GUIDE.md`](SETUP_GUIDE.md)
- Architecture & features â†’ This README
- Backend API â†’ [`backend-server/README.md`](backend-server/README.md)

**Logs to Check:**
- Backend: Terminal where server is running
- Extensions: Browser console (F12)
- Network: Chrome DevTools â†’ Network tab â†’ WS

---

## ğŸ‰ You're Ready!

### System Overview:
1. **Backend Server** aggregates emotion data
2. **Student Extension** analyzes own video
3. **Teacher Extension** displays aggregated results
4. **Gemini AI** provides teaching insights

### Key Benefits:
âœ… Tab-independent operation
âœ… Enhanced student privacy
âœ… Real-time emotion aggregation
âœ… AI-powered insights
âœ… Production-ready architecture

**Get started:** Follow the installation steps above or see [`SETUP_GUIDE.md`](SETUP_GUIDE.md) for detailed instructions.

---

**Built for VNR Hackathon 2025** ğŸš€

**Revolutionizing virtual classrooms with emotion awareness!** ğŸ“šğŸ§ 
